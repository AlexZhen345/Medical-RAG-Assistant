import sys
import os

# --- 1. è·¯å¾„ä¸é…ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
root_dir = os.path.dirname(current_dir)
sys.path.append(root_dir)

import config
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer, util
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, roc_auc_score
import torch
import joblib

# å®šä¹‰æ¨¡å‹ä¿å­˜è·¯å¾„ (ä¿å­˜åœ¨æ ¹ç›®å½•)
VERIFIER_MODEL_PATH = os.path.join(config.ROOT_DIR, "verifier_model.pkl")

# 1ï¸âƒ£ åŠ è½½æ•°æ®
def load_data(path):
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {path}")
    df = pd.read_excel(path)
    print(f"âœ… [Verifier] Loaded {len(df)} samples from {path}")
    return df

# 2ï¸âƒ£ è®¡ç®—è¯­ä¹‰ç‰¹å¾
def compute_semantic_features(df, model_name=config.EMBEDDING_MODEL_PATH):
    print(f"âš™ï¸ [Verifier] è®¡ç®—è¯­ä¹‰ç‰¹å¾ (ä½¿ç”¨æ¨¡å‹: {model_name})...")
    model = SentenceTransformer(model_name)

    sims_gt_ma, sims_q_ma, sims_q_gt = [], [], []
    for _, row in df.iterrows():
        gt, ma, q = str(row["GroundTruth"]), str(row["ModelAnswer"]), str(row["Question"])
        
        emb_gt = model.encode(gt, convert_to_tensor=True)
        emb_ma = model.encode(ma, convert_to_tensor=True)
        emb_q = model.encode(q, convert_to_tensor=True)

        sims_gt_ma.append(float(util.cos_sim(emb_gt, emb_ma)))
        sims_q_ma.append(float(util.cos_sim(emb_q, emb_ma)))
        sims_q_gt.append(float(util.cos_sim(emb_q, emb_gt)))

    df["sim_gt_ma"] = sims_gt_ma
    df["sim_q_ma"] = sims_q_ma
    df["sim_q_gt"] = sims_q_gt
    df["len_diff"] = df["ModelAnswer"].apply(lambda x: len(str(x))) - df["GroundTruth"].apply(lambda x: len(str(x)))
    print("âœ… [Verifier] è¯­ä¹‰ç‰¹å¾è®¡ç®—å®Œæˆã€‚")
    return df

# 3ï¸âƒ£ ä¸­æ–‡ Roberta NLI ç‰¹å¾
def compute_nli_features(df, model_name=config.NLI_MODEL_PATH, max_samples=None):
    print(f"âš™ï¸ [Verifier] è®¡ç®— NLI é€»è¾‘ç‰¹å¾ (ä½¿ç”¨æ¨¡å‹: {model_name})...")
    
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
    except Exception as e:
        print(f"âŒ NLI æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥ config.py ä¸­çš„ NLI_MODEL_PATH æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è¿è¡Œ scripts/download_models.py")
        raise e
        
    model.eval()

    entail_probs, contra_probs = [], []

    for i, row in df.iterrows():
        if max_samples and i >= max_samples:
            entail_probs.append(0.0)
            contra_probs.append(0.0)
            continue

        premise = str(row["GroundTruth"])
        hypothesis = str(row["ModelAnswer"])
        
        inputs = tokenizer(premise, hypothesis, return_tensors='pt',
                           truncation=True, max_length=512, padding='max_length')
        
        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=1)[0].numpy()

        # Roberta-NLI çš„ç±»åˆ«é¡ºåºä¸€èˆ¬ä¸º [entailment, neutral, contradiction]
        # æ³¨æ„ï¼šä¸åŒæ¨¡å‹çš„è¾“å‡ºé¡ºåºå¯èƒ½ä¸åŒï¼Œè¿™é‡Œå‡è®¾ç¬¦åˆè¯¥é¡ºåº
        entail_probs.append(float(probs[0]))
        contra_probs.append(float(probs[2]))

        if i % 20 == 0:
            print(f"  Processed {i+1}/{len(df)} samples")

    df["nli_entail"] = entail_probs
    df["nli_contra"] = contra_probs
    print("âœ… [Verifier] NLI ç‰¹å¾è®¡ç®—å®Œæˆã€‚")
    return df

# 4ï¸âƒ£ è®­ç»ƒåˆ†ç±»å™¨
def train_verifier(df):
    features = ["sim_gt_ma", "sim_q_ma", "sim_q_gt", "len_diff", "nli_entail", "nli_contra"]
    
    # ç®€å•çš„ç©ºå€¼å¤„ç†
    df = df.dropna(subset=features + ["HallucinationLabel"])
    
    X = df[features].values
    y = df["HallucinationLabel"].astype(int)

    print("âš™ï¸ [Verifier] æ­£åœ¨è®­ç»ƒé€»è¾‘å›å½’åˆ†ç±»å™¨...")
    clf = LogisticRegression(class_weight="balanced", max_iter=1000, random_state=42)
    clf.fit(X, y)

    y_pred = clf.predict(X)
    y_score = clf.predict_proba(X)[:, 1]
    
    try:
        auc = roc_auc_score(y, y_score)
        print(f"âœ… AUC: {auc:.3f}")
    except:
        print("âš ï¸ æ ·æœ¬å¤ªå°‘æˆ–å•ä¸€ï¼Œæ— æ³•è®¡ç®— AUC")
        
    print(classification_report(y, y_pred, digits=3))

    joblib.dump(clf, VERIFIER_MODEL_PATH)
    print(f"âœ… [Verifier] æ¨¡å‹å·²ä¿å­˜è‡³: {VERIFIER_MODEL_PATH}")
    return clf

# 5ï¸âƒ£ æ ¸å¿ƒéªŒè¯ç±»
class HallucinationVerifier:
    def __init__(self,
                 embed_model=config.EMBEDDING_MODEL_PATH,
                 nli_model=config.NLI_MODEL_PATH):
        
        print("âš™ï¸ [Verifier] åˆå§‹åŒ–éªŒè¯å™¨...")
        self.embedder = SentenceTransformer(embed_model)
        self.tokenizer = AutoTokenizer.from_pretrained(nli_model)
        self.nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model)
        
        if os.path.exists(VERIFIER_MODEL_PATH):
            self.classifier = joblib.load(VERIFIER_MODEL_PATH)
            print("âœ… [Verifier] å·²åŠ è½½é¢„è®­ç»ƒçš„åˆ†ç±»å™¨ã€‚")
        else:
            print("âš ï¸ [Verifier] æœªæ‰¾åˆ°é¢„è®­ç»ƒåˆ†ç±»å™¨ (verifier_model.pkl)ã€‚è¯·å…ˆè¿è¡Œ train_verifier()ã€‚")
            self.classifier = None

    def verify(self, question, model_answer, groundtruth):
        """è¾“å…¥é—®é¢˜ã€AIå›ç­”ã€æ­£ç¡®ç­”æ¡ˆ â†’ è¾“å‡ºäº‹å®ä¸€è‡´æ€§åˆ†æ•°"""
        if self.classifier is None:
            return {"fact_consistency_score": 0.0, "label": "unknown (no model)", "notes": []}

        # è®¡ç®—è¯­ä¹‰ç‰¹å¾
        emb_gt = self.embedder.encode(str(groundtruth), convert_to_tensor=True)
        emb_ma = self.embedder.encode(str(model_answer), convert_to_tensor=True)
        emb_q = self.embedder.encode(str(question), convert_to_tensor=True)

        sim_gt_ma = float(util.cos_sim(emb_gt, emb_ma))
        sim_q_ma = float(util.cos_sim(emb_q, emb_ma))
        sim_q_gt = float(util.cos_sim(emb_q, emb_gt))
        len_diff = len(str(model_answer)) - len(str(groundtruth))

        # è®¡ç®— NLI ç‰¹å¾
        inputs = self.tokenizer(str(groundtruth), str(model_answer), return_tensors='pt',
                                truncation=True, max_length=512, padding='max_length')
        with torch.no_grad():
            probs = torch.softmax(self.nli_model(**inputs).logits, dim=1)[0].numpy()
        nli_entail, nli_contra = float(probs[0]), float(probs[2])

        # é¢„æµ‹
        X = np.array([[sim_gt_ma, sim_q_ma, sim_q_gt, len_diff, nli_entail, nli_contra]])
        score = self.classifier.predict_proba(X)[0, 1]
        
        # å®šä¹‰é˜ˆå€¼ï¼Œåˆ†æ•°è¶Šé«˜è¶Šconsistent (éå¹»è§‰)
        label = "consistent" if score >= 0.5 else "hallucination"

        return {
            "fact_consistency_score": round(score, 3),
            "label": label,
            "notes": [
                f"sim(gt,ma)={sim_gt_ma:.2f}",
                f"nli_entail={nli_entail:.2f}",
                f"nli_contra={nli_contra:.2f}"
            ]
        }

def load_or_process_data(data_path, processed_path):
    """åŠ è½½æˆ–é‡æ–°å¤„ç†æ•°æ®"""
    if os.path.exists(processed_path):
        print(f"ğŸ“ [Verifier] å‘ç°å·²å¤„ç†æ•°æ®: {processed_path}")
        return pd.read_excel(processed_path)
    else:
        print("ğŸ”„ [Verifier] æœªæ‰¾åˆ°ç¼“å­˜ï¼Œå¼€å§‹å¤„ç†åŸå§‹æ•°æ®...")
        df = load_data(data_path)
        df = compute_semantic_features(df)
        df = compute_nli_features(df, max_samples=None)
        df.to_excel(processed_path, index=False)
        print(f"ğŸ’¾ [Verifier] å¤„ç†å®Œæˆå¹¶ä¿å­˜è‡³: {processed_path}")
        return df

# 6ï¸âƒ£ å•å…ƒæµ‹è¯•
if __name__ == "__main__":
    # ä½¿ç”¨ config ä¸­çš„è·¯å¾„è¿›è¡Œæµ‹è¯•
    data_path = config.HALLUCINATION_DATA_PATH
    processed_path = config.HALLUCINATION_PROCESSED_PATH

    print("\n--- Verifier å•å…ƒæµ‹è¯• ---")
    
    if os.path.exists(data_path):
        # 1. å‡†å¤‡æ•°æ®
        df = load_or_process_data(data_path, processed_path)
        
        # 2. è®­ç»ƒæ¨¡å‹
        train_verifier(df)

        # 3. éªŒè¯å•æ¡
        verifier = HallucinationVerifier()
        result = verifier.verify(
            "ç³–å°¿ç—…æ‚£è€…é€‚åˆåƒä»€ä¹ˆä¸»é£Ÿï¼Ÿ",
            "ç³–å°¿ç—…æ‚£è€…åº”å¤šåƒç³¯ç±³å’Œçº¢è–¯ã€‚",
            "ç³–å°¿ç—…æ‚£è€…åº”é¿å…ç³¯ç±³ç­‰é«˜å‡ç³–é£Ÿç‰©ã€‚"
        )
        print("\nâœ… æµ‹è¯•ç»“æœï¼š", result)
    else:
        print(f"âŒ æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {data_path}ï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•ã€‚")
