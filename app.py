import sys
import os
import time

# --- 1. æ ¸å¿ƒè·¯å¾„é…ç½® (ç¡®ä¿èƒ½å¯¼å…¥ src å’Œ config) ---
# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨çš„ç›®å½• (é¡¹ç›®æ ¹ç›®å½•)
current_dir = os.path.dirname(os.path.abspath(__file__))
# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥åˆ° Python çš„æœç´¢è·¯å¾„ä¸­ï¼Œè¿™æ ·æ‰èƒ½å¯¼å…¥ config.py å’Œ src åŒ…
sys.path.append(current_dir)

# å¯¼å…¥é…ç½®æ–‡ä»¶ (ä¸€å®šè¦æœ‰ config.py)
try:
    import config
except ImportError:
    raise ImportError("âŒ æ‰¾ä¸åˆ° config.pyï¼è¯·ç¡®ä¿ä½ å·²ç»æŒ‰ç…§æ•™ç¨‹åˆ›å»ºäº† config.py æ–‡ä»¶ã€‚")

import gradio as gr

# ä» src åŒ…ä¸­å¯¼å…¥æ¨¡å—
from src.rag import MedicalRAG
from src.inference import get_medical_answer, get_normal_answer
from src.verifier import HallucinationVerifier, load_or_process_data, train_verifier

# --- 2. ä¸šåŠ¡é€»è¾‘ç®¡é“ ---
def rag_pipeline(question, top_k=3):
    """
    å¤„ç†ç”¨æˆ·è¯·æ±‚çš„ä¸»ç®¡é“ï¼šæ£€ç´¢ -> ç”Ÿæˆ -> éªŒè¯
    """
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()

    # 1. æ£€ç´¢ç›¸å…³çŸ¥è¯† (RAG)
    # è°ƒç”¨ RAG æ¨¡å—ï¼Œæ‰¾å›æœ€ç›¸å…³çš„ top_k æ¡çŸ¥è¯†
    response = embedding_model.rag_retrieve(question, top_k=top_k, return_full_answer=True)
    
    if response['success']:
        knowledge_contexts = [result.get('answer') for result in response['results']]
        # æ ¼å¼åŒ–å‚è€ƒèµ„æ–™æ–‡æœ¬ï¼Œç”¨äºå±•ç¤º
        contexts_text = "\n".join([f"{i+1}. {ctx}" for i, ctx in enumerate(knowledge_contexts)])
    else:
        knowledge_contexts = []
        contexts_text = "æœªæ£€ç´¢åˆ°ç›¸å…³çŸ¥è¯†ã€‚"

    # 2. ç”Ÿæˆå›ç­” (LLM)
    context_str = "\n".join(knowledge_contexts) # æ‹¼æ¥å¾…ä¼šå„¿è¦å–‚ç»™æ¨¡å‹çš„ä¸Šä¸‹æ–‡
    
    # è¯•å·Aï¼šåŒ»å­¦å›ç­” (åŸºäºRAG)
    answer1 = get_medical_answer(question, context_str)
    # è¯•å·Bï¼šæ™®é€šå›ç­” (è£¸å¥”)
    answer2 = get_normal_answer(question, "")

    # 3. äº‹å®ä¸€è‡´æ€§æ£€æŸ¥ (Verifier)
    # åªæœ‰å½“æœ‰å‚è€ƒèµ„æ–™æ—¶ï¼Œæ£€æŸ¥æ‰æœ‰æ„ä¹‰
    if knowledge_contexts:
        consistency_result = verifier.verify(question, answer1, context_str)
        # æå–åˆ†æ•°å’Œæ ‡ç­¾
        score_val = consistency_result.get('fact_consistency_score', 0)
        consistency_msg = f"{score_val:.2f} ({consistency_result.get('label', 'unknown')})"
        
        # å¦‚æœåˆ†æ•°å¤ªä½ï¼ŒåŠ ä¸ªè­¦å‘Š
        if score_val < 0.5:
            consistency_msg += " âš ï¸ è­¦å‘Šï¼šå¯ä¿¡åº¦ä½ï¼"
    else:
        consistency_msg = "N/A (æ— å‚è€ƒèµ„æ–™)"

    # è®¡ç®—æ€»è€—æ—¶
    total_time = round(time.time() - start_time, 2)

    # 4. æœ€ç»ˆç»“æœæ‹¼è£…
    final_output = (
        f"### ğŸ’Š åŒ»å­¦å›ç­” (RAGå¢å¼º)\n{answer1}\n\n"
        f"---\n"
        f"### ğŸ¤– æ™®é€šå›ç­” (æ— çŸ¥è¯†åº“)\n{answer2}\n\n"
        f"---\n"
        f"### ğŸ“š æ£€ç´¢åˆ°çš„çŸ¥è¯†ç‰‡æ®µ\n{contexts_text}\n\n"
        f"---\n"
        f"### âš–ï¸ äº‹å®ä¸€è‡´æ€§è¯„åˆ†\n{consistency_msg}\n\n"
        f"â±ï¸ æ€»å¤„ç†æ—¶é—´: {total_time}ç§’"
    )
    
    return final_output


# --- 3. ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    print("\nğŸš€ æ­£åœ¨å¯åŠ¨ Medical RAG System...")
    print(f"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {config.ROOT_DIR}")

    # --- åˆå§‹åŒ–ç»„ä»¶ A: RAG æ£€ç´¢æ¨¡å— ---
    print("æ­£åœ¨åŠ è½½ RAG æ¨¡å—...")
    
    # æ™ºèƒ½æ£€æŸ¥ï¼šå¦‚æœç´¢å¼•æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œæˆ–è€…é‡Œé¢æ˜¯ç©ºçš„ï¼Œå°±å…ˆæ„å»ºç´¢å¼•
    if not os.path.exists(config.INDEX_DIR) or not os.listdir(config.INDEX_DIR):
        print(f"âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆç´¢å¼•ï¼Œæ­£åœ¨ä» {config.VAL_DATA_PATH} æ„å»º...")
        if os.path.exists(config.VAL_DATA_PATH):
            temp_rag = MedicalRAG(model_name=config.EMBEDDING_MODEL_PATH)
            temp_rag.load_knowledge_from_jsonl(config.VAL_DATA_PATH)
            temp_rag.build_index(save_path=config.INDEX_DIR)
            print("âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼")
        else:
            print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ {config.VAL_DATA_PATH}ï¼Œæ— æ³•æ„å»ºç´¢å¼•ã€‚")
    
    # æ­£å¼åŠ è½½ RAG
    embedding_model = MedicalRAG(
        model_name=config.EMBEDDING_MODEL_PATH,
        index_path=config.INDEX_DIR
    )

    # --- åˆå§‹åŒ–ç»„ä»¶ B: Verifier éªŒè¯æ¨¡å— ---
    print("æ­£åœ¨åŠ è½½ Verifier æ¨¡å—...")
    
    # åŠ è½½å¹¶è®­ç»ƒè£åˆ¤æ•°æ®
    if os.path.exists(config.HALLUCINATION_DATA_PATH):
        df = load_or_process_data(
            data_path=config.HALLUCINATION_DATA_PATH,
            processed_path=config.HALLUCINATION_PROCESSED_PATH
        )
        train_verifier(df)
        
        # å®ä¾‹åŒ–è£åˆ¤
        verifier = HallucinationVerifier(
            embed_model=config.EMBEDDING_MODEL_PATH,
            nli_model=config.NLI_MODEL_PATH
        )
    else:
        print(f"âš ï¸ è­¦å‘Šï¼šæ‰¾ä¸åˆ° {config.HALLUCINATION_DATA_PATH}ï¼ŒéªŒè¯åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨ã€‚")
        verifier = None # é˜²æ­¢æŠ¥é”™

    print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼æ­£åœ¨å¯åŠ¨ç½‘é¡µç•Œé¢...")

    # --- 4. Gradio ç•Œé¢æ­å»º ---
    with gr.Blocks(title="åŒ»å­¦æ™ºèƒ½é—®ç­”ç³»ç»Ÿ") as demo:
        gr.Markdown("# ğŸ¥ Medical RAG - åŒ»å­¦æ™ºèƒ½é—®ç­”åŠ©æ‰‹")
        gr.Markdown("æœ¬é¡¹ç›®åŸºäº RAG æŠ€æœ¯ + Qwen å¤§æ¨¡å‹ï¼Œæä¾›å‡†ç¡®çš„åŒ»å­¦çŸ¥è¯†é—®ç­”ï¼Œå¹¶å†…ç½®å¹»è§‰æ£€æµ‹æœºåˆ¶ã€‚")

        with gr.Row():
            # å·¦ä¾§è¾“å…¥åŒº
            with gr.Column(scale=4):
                question_input = gr.Textbox(
                    label="ğŸ‘©â€âš•ï¸ è¯·è¾“å…¥ä½ çš„åŒ»å­¦é—®é¢˜",
                    placeholder="ä¾‹å¦‚ï¼šæ„Ÿå†’äº†èƒ½åƒé˜¿å¸åŒ¹æ—å—ï¼Ÿç³–å°¿ç—…æœ‰ä»€ä¹ˆå¿Œå£ï¼Ÿ",
                    lines=3
                )
                
                with gr.Row():
                    top_k_slider = gr.Slider(
                        minimum=1, maximum=5, value=3, step=1, 
                        label="æ£€ç´¢çŸ¥è¯†æ¡æ•° (Top-K)"
                    )
                    
                submit_btn = gr.Button("ğŸ” å¼€å§‹åˆ†æ", variant="primary", size="lg")
                
                # ç¤ºä¾‹é—®é¢˜
                gr.Examples(
                    examples=[
                        ["ç³–å°¿ç—…çš„ç—‡çŠ¶åŒ…æ‹¬å‘çƒ§å—ï¼Ÿ"],
                        ["è‚ºç»“æ ¸æ˜¯ç”±ä»€ä¹ˆç—…åŸä½“å¯¼è‡´çš„ï¼Ÿ"],
                        ["é«˜è¡€å‹æ‚£è€…åº”è¯¥æ³¨æ„é¥®é£Ÿå—ï¼Ÿ"],
                        ["æ„Ÿå†’äº†åƒä»€ä¹ˆè¯å¥½å¾—å¿«ï¼Ÿ"]
                    ],
                    inputs=question_input
                )

            # å³ä¾§è¾“å‡ºåŒº
            with gr.Column(scale=6):
                answer_output = gr.Markdown(label="ğŸ“‹ åˆ†ææŠ¥å‘Š")

        # ç»‘å®šäº‹ä»¶
        submit_btn.click(
            fn=rag_pipeline,
            inputs=[question_input, top_k_slider],
            outputs=answer_output
        )
        
        # æ”¯æŒå›è½¦æäº¤
        question_input.submit(
            fn=rag_pipeline,
            inputs=[question_input, top_k_slider],
            outputs=answer_output
        )

    # å¯åŠ¨æœåŠ¡
    demo.launch(server_name="127.0.0.1", share=False, inbrowser=True)